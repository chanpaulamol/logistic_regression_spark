{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq69kjx/zoTkyIsVDEhfLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanpaulamol/logistic_regression_spark/blob/main/heart_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Members: Lelyta, Noora , Chan\n",
        "#### Project: Logistic Regression using spark to predict heart disease!\n",
        "#### Course: Big Data"
      ],
      "metadata": {
        "id": "xKm4UKp_jkYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impport the Drive from google.colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the Drive to access the CSV file\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DDxVskijiyg",
        "outputId": "477072c3-a8dc-4685-fdd9-8352642625e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# uncomment to install pyspark "
      ],
      "metadata": {
        "id": "ymvNMwLOro_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt-Ouj-ulAK_",
        "outputId": "c1208959-1a56-4a45-94d8-cbeae3e4f25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=015520ca3736b8f39449499a142a63b8e229cec33f57c41c479edf1276036545\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "EfXg6klKlebC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "2pk3iwZ6lCi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Spark Session"
      ],
      "metadata": {
        "id": "7B6WqfxYmQkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark session\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "zymI5t8hmUXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "N5aJ1jzZmYhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "data = spark.read.csv('/content/drive/MyDrive/spark_dataset/heart_dataset.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "i9g_NgUSmdVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data"
      ],
      "metadata": {
        "id": "3riocCQenFxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB4-YvsSnAnt",
        "outputId": "f75ad9e9-7a0a-42b7-e991-225c1f7241e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---------+---------+-----------+---------+-------+-----+--------------+------------+-----+------------+-----------+------+\n",
            "|Age|Sex|ChestPain|RestingBP|Cholesterol|FastingBS|RestECG|MaxHR|ExerciseAngina|STDepression|Slope|MajorVessels|Thalassemia|Target|\n",
            "+---+---+---------+---------+-----------+---------+-------+-----+--------------+------------+-----+------------+-----------+------+\n",
            "| 52|  1|        0|      125|        212|        0|      1|  168|             0|         1.0|    2|           2|          3|     0|\n",
            "| 53|  1|        0|      140|        203|        1|      0|  155|             1|         3.1|    0|           0|          3|     0|\n",
            "| 70|  1|        0|      145|        174|        0|      1|  125|             1|         2.6|    0|           0|          3|     0|\n",
            "| 61|  1|        0|      148|        203|        0|      1|  161|             0|         0.0|    2|           1|          3|     0|\n",
            "| 62|  0|        0|      138|        294|        1|      1|  106|             0|         1.9|    1|           3|          2|     0|\n",
            "| 58|  0|        0|      100|        248|        0|      0|  122|             0|         1.0|    1|           0|          2|     1|\n",
            "| 58|  1|        0|      114|        318|        0|      2|  140|             0|         4.4|    0|           3|          1|     0|\n",
            "| 55|  1|        0|      160|        289|        0|      0|  145|             1|         0.8|    1|           1|          3|     0|\n",
            "| 46|  1|        0|      120|        249|        0|      0|  144|             0|         0.8|    2|           0|          3|     0|\n",
            "| 54|  1|        0|      122|        286|        0|      0|  116|             1|         3.2|    1|           2|          2|     0|\n",
            "| 71|  0|        0|      112|        149|        0|      1|  125|             0|         1.6|    1|           0|          2|     1|\n",
            "| 43|  0|        0|      132|        341|        1|      0|  136|             1|         3.0|    1|           0|          3|     0|\n",
            "| 34|  0|        1|      118|        210|        0|      1|  192|             0|         0.7|    2|           0|          2|     1|\n",
            "| 51|  1|        0|      140|        298|        0|      1|  122|             1|         4.2|    1|           3|          3|     0|\n",
            "| 52|  1|        0|      128|        204|        1|      1|  156|             1|         1.0|    1|           0|          0|     0|\n",
            "| 34|  0|        1|      118|        210|        0|      1|  192|             0|         0.7|    2|           0|          2|     1|\n",
            "| 51|  0|        2|      140|        308|        0|      0|  142|             0|         1.5|    2|           1|          2|     1|\n",
            "| 54|  1|        0|      124|        266|        0|      0|  109|             1|         2.2|    1|           1|          3|     0|\n",
            "| 50|  0|        1|      120|        244|        0|      1|  162|             0|         1.1|    2|           0|          2|     1|\n",
            "| 58|  1|        2|      140|        211|        1|      0|  165|             0|         0.0|    2|           0|          2|     1|\n",
            "+---+---+---------+---------+-----------+---------+-------+-----+--------------+------------+-----+------------+-----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extraction"
      ],
      "metadata": {
        "id": "1YMeNUw7owRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input features\n",
        "feature_columns = ['Age', 'Sex', 'ChestPain', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestECG',\n",
        "                   'MaxHR', 'ExerciseAngina', 'STDepression', 'Slope', 'MajorVessels', 'Thalassemia']\n",
        "\n",
        "# Create a VectorAssembler to combine the input features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "\n",
        "# Transform the data by assembling the input features\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Create a StandardScaler to scale the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
        "\n",
        "# Fit and transform the data using the scaler\n",
        "scaled_data = scaler.fit(data).transform(data)\n",
        "\n",
        "# Select the scaled features and target column for further processing\n",
        "selected_data = scaled_data.select('scaled_features', 'Target')\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "selected_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cre3_JOGoq_4",
        "outputId": "a3a7d22d-5eb6-4e73-cdcc-6e7c6add2223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|     scaled_features|Target|\n",
            "+--------------------+------+\n",
            "|[5.73173902764403...|     0|\n",
            "|[5.84196477817564...|     0|\n",
            "|[7.71580253721311...|     0|\n",
            "|[6.72377078242857...|     0|\n",
            "|[6.83399653296019...|     0|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|[6.39309353083372...|     0|\n",
            "|[6.06241627923887...|     0|\n",
            "|[5.07038452445433...|     0|\n",
            "|[5.95219052870726...|     0|\n",
            "|[7.82602828774473...|     1|\n",
            "|[4.73970727285948...|     0|\n",
            "|[3.74767551807494...|     1|\n",
            "|[5.62151327711241...|     0|\n",
            "|[5.73173902764403...|     0|\n",
            "|[3.74767551807494...|     1|\n",
            "|[5.62151327711241...|     1|\n",
            "|[5.95219052870726...|     0|\n",
            "|[5.5112875265808,...|     1|\n",
            "|[6.39309353083372...|     1|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "cMVdT4LNpOsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (70% for training, 30% for testing)\n",
        "train_data, test_data = selected_data.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "# Show the resulting DataFrames\n",
        "print(\"Training Data:\")\n",
        "train_data.show()\n",
        "print(\"Testing Data:\")\n",
        "test_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rppeOz37pS3b",
        "outputId": "8f4fc7c4-d63d-4f10-9fb1-76ecd1681dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "+--------------------+------+\n",
            "|     scaled_features|Target|\n",
            "+--------------------+------+\n",
            "|(13,[0,1,3,4,7,10...|     0|\n",
            "|(13,[0,1,3,4,7,10...|     0|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Testing Data:\n",
            "+--------------------+------+\n",
            "|     scaled_features|Target|\n",
            "+--------------------+------+\n",
            "|(13,[0,1,3,4,7,10...|     0|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,1,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,2,3,4,7,10...|     1|\n",
            "|(13,[0,3,4,6,7,10...|     1|\n",
            "|(13,[0,3,4,7,8,10...|     1|\n",
            "|(13,[0,3,4,7,8,10...|     1|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|(13,[0,3,4,7,9,10...|     1|\n",
            "|(13,[0,3,4,7,9,11...|     0|\n",
            "|(13,[0,3,4,7,9,11...|     0|\n",
            "|(13,[0,3,4,7,10,1...|     1|\n",
            "|(13,[0,3,4,7,10,1...|     1|\n",
            "|(13,[0,3,4,7,10,1...|     0|\n",
            "|(13,[0,3,4,7,10,1...|     0|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "o8MZ1OLupyRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of LogisticRegression\n",
        "model = LogisticRegression(labelCol='Target', featuresCol='scaled_features')\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr_model = model.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Show the predictions\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14fF603Yp1jQ",
        "outputId": "501ead21-5eb1-460c-ac70-601cb925f93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "|     scaled_features|Target|       rawPrediction|         probability|prediction|\n",
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "|(13,[0,1,3,4,7,10...|     0|[-0.8471861079950...|[0.30002346852686...|       1.0|\n",
            "|(13,[0,1,3,4,7,10...|     1|[-1.9392014945617...|[0.12573560692610...|       1.0|\n",
            "|(13,[0,1,3,4,7,10...|     1|[-1.1538191161639...|[0.23979219741835...|       1.0|\n",
            "|(13,[0,2,3,4,7,10...|     1|[-4.8386138646432...|[0.00785581934885...|       1.0|\n",
            "|(13,[0,2,3,4,7,10...|     1|[-4.8386138646432...|[0.00785581934885...|       1.0|\n",
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "QpEEHFTMrAiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Target', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "\n",
        "# Evaluate the model using precision, recall, and F1-score\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Target', predictionCol='prediction',\n",
        "                                              metricName='weightedPrecision')\n",
        "precision = evaluator.evaluate(predictions)\n",
        "evaluator.setMetricName('weightedRecall')\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator.setMetricName('f1')\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1-Score: {:.2f}\".format(f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm5JLpDtrCoC",
        "outputId": "461196d5-4f34-407b-e603-1dc8dbd7a68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n",
            "Precision: 0.87\n",
            "Recall: 0.86\n",
            "F1-Score: 0.86\n"
          ]
        }
      ]
    }
  ]
}